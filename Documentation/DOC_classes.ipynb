{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Directory of clean_cresci_2015.py to sys.path\n",
    "sys.path.append(os.path.abspath(\"git/clean_cresci_2015.py\"))\n",
    "\n",
    "# import clean_cresci_2015\n",
    "from clean_cresci_2015 import clean_cresci_2015\n",
    "from import_data import ImportData\n",
    "from evaluation import Evaluate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Cresci-2015 Dataset\n",
    "\n",
    "## Overview\n",
    "This script is designed to clean and preprocess the Cresci-2015 dataset, which consists of Twitter data related to social bots and genuine users. The script performs various data cleaning and preprocessing steps to prepare the data for further analysis or machine learning tasks.\n",
    "\n",
    "## Dependencies\n",
    "- pandas: Data manipulation library in Python.\n",
    "- numpy: Numerical computing library in Python.\n",
    "- os: Operating system interface for file operations.\n",
    "- datetime: Library for manipulating dates and times in Python.\n",
    "- sklearn.preprocessing.MinMaxScaler: Class for scaling numerical features to a specified range.\n",
    "- sklearn.model_selection.train_test_split: Function for splitting data into training and testing sets.\n",
    "\n",
    "### Methods\n",
    "- `clean_data`\n",
    "Cleans the dataset by loading data from CSV files, selecting important features, converting data types, and filling missing values.\n",
    "\n",
    "### Steps Performed:\n",
    "\n",
    "1. **Loading Data**: \n",
    "   - The script loads tweet and user data from CSV files located in subdirectories of the base directory specified as `base_directory`.\n",
    "\n",
    "2. **Feature Selection**:\n",
    "   - Selects relevant features from both tweet and user datasets.\n",
    "\n",
    "3. **Data Type Conversion**:\n",
    "   - Converts the 'created_at' column in the users dataset to datetime format.\n",
    "\n",
    "4. **Handling Missing Values**:\n",
    "   - Fills missing values with zeros for numeric columns in both tweet and user datasets.\n",
    "\n",
    "5. **Feature Engineering**:\n",
    "   - Calculates additional features such as 'account_age_years', 'followers_to_friends_ratio' in the users dataset.\n",
    "   - Calculates tweet-level features such as 'retweet_ratio' and 'reply_ratio'.\n",
    "\n",
    "6. **Normalization**:\n",
    "   - Scales numeric features in both tweet and user datasets to a range between 0 and 1 using Min-Max scaling.\n",
    "\n",
    "7. **Data Merging**:\n",
    "   - Merges the tweet and user datasets on the 'user_id' and 'id' columns respectively.\n",
    "\n",
    "8. **Bot Labeling**:\n",
    "   - Adds a binary 'bot' label based on the folder name.\n",
    "\n",
    "9. **Saving Cleaned Data**:\n",
    "   - Saves the cleaned and processed dataframes as CSV files in a 'clean' subdirectory within each dataset's folder.\n",
    "\n",
    "### Returns:\n",
    "- None. The method adjusts the DataFrame in place.\n",
    "\n",
    "### Error Handling\n",
    "- **FileNotFoundError**: This error may occur if the base directory does not exist or is incorrect. Ensure the directory path is correct and accessible.\n",
    "\n",
    "- **DataError**: If there are issues in data consistency such as missing columns needed for selected features, the method will raise this error.\n",
    "\n",
    "## Example Usage:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the cleaner\n",
    "cleaner = clean_cresci_2015()\n",
    "\n",
    "# Specify the base directory if different from the default\n",
    "cleaner.clean_data(base_directory=\"git/cresci-2015.csv/\")\n",
    "\n",
    "# Clean the data\n",
    "dataset_cleaner.clean_data(base_directory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics and Visualization\n",
    "\n",
    "## Overview\n",
    "This script defines a class `Evaluate`. This class provides tools for assessing the performance of machine learning models on Twitter data. It includes methods for calculating various performance metrics, visualizing results, and interpreting the effectiveness of model predictions.\n",
    "\n",
    "## Dependencies\n",
    "- pandas: Data manipulation library in Python.\n",
    "- numpy: Numerical computing library in Python.\n",
    "- matplotlib.pyplot: Plotting library in Python.\n",
    "- seaborn: Statistical data visualization library based on matplotlib.\n",
    "- sklearn.metrics: Collection of metrics to evaluate the performance of machine learning models.\n",
    "\n",
    "## Class: Evaluate\n",
    "The `Evaluate` class encapsulates methods to compute detailed evaluation metrics and visualize the performance of binary classifiers:\n",
    "\n",
    "**Metrics Provided**\n",
    "1. **Accuracy**: Reflects the overall correctness of the model.\n",
    "2. **Confusion Matrix**: Computes the confusion matrix rates (True Negative Rate, False Positive Rate, False Negative Rate, True Positive Rate).\n",
    "3. **Precision**: Indicates the accuracy of positive predictions.\n",
    "4. **Recall**: Measures the ability of the model to find all relevant instances.\n",
    "5. **F1 Score**: Computes the F1 score, which is the harmonic mean of precision and recall.\n",
    "6. **Matthews Correlation Coefficient (MCC)**: Computes the MCC, which measures the correlation between predicted and true binary classifications.\n",
    "7. **Area Under the ROC Curve (AUC)**: Computes the AUC score, which measures the area under the Receiver Operating Characteristic (ROC) curve.\n",
    "\n",
    "**Visualization Methods**\n",
    "- **Plot Confusion Matrix**: Visualizes the confusion matrix in a color-coded format to aid in quick interpretation.\n",
    "- **Plot ROC Curve**: Illustrates the diagnostic ability of the binary classifier system as its discrimination threshold varies.\n",
    "\n",
    "Additionally, the class provides methods to:\n",
    "- Get all evaluation metrics at once.\n",
    "- Plot the confusion matrix.\n",
    "- Plot the ROC curve.\n",
    "\n",
    "## Usage\n",
    "1. Instantiate the `Evaluate` class with true values and predicted values.\n",
    "2. Optionally, provide predicted probabilities for computing AUC.\n",
    "3. Call individual metric methods or use `get_all_metrics` to obtain all metrics at once.\n",
    "4. Use `plot_confusion_matrix` to visualize the confusion matrix.\n",
    "5. Use `plot_roc_curve` to visualize the ROC curve.\n",
    "\n",
    "## Example Usage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_values = [0, 1, 1, 0, 1, 0, 0, 1]\n",
    "predicted_values = [0, 1, 1, 0, 1, 0, 1, 1]\n",
    "predicted_probabilities = [0.1, 0.9, 0.7, 0.2, 0.8, 0.3, 0.6, 0.4]\n",
    "\n",
    "evaluator = Evaluate(true_values, predicted_values, predicted_probabilities)\n",
    "print(evaluator.get_all_metrics())\n",
    "\n",
    "evaluator.plot_confusion_matrix()\n",
    "evaluator.plot_roc_curve()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Splitting\n",
    "\n",
    "## Overview\n",
    "This script provides functionality for importing data from the Cresci-2015 dataset and splitting it into training, testing, and validation sets. It also allows for sampling the data based on specified bot ratios.\n",
    "\n",
    "## Dependencies\n",
    "- `os`: Operating system interface for file operations.\n",
    "- `pandas`: Data manipulation library in Python.\n",
    "- `sklearn.model_selection.train_test_split`: Function for splitting data into training and testing sets.\n",
    "\n",
    "## Class: ImportData\n",
    "This class contains methods to perform the following tasks:\n",
    "\n",
    "### Data Typing\n",
    "- Determines the type of data to import based on the provided parameter.\n",
    "\n",
    "### Reading and Sampling Data\n",
    "- Reads the non-bot and bot dataframes from CSV files.\n",
    "- Samples the bot data based on specified bot ratios and combines it with non-bot data.\n",
    "\n",
    "### Splitting Dataset\n",
    "- Splits the dataset into training, testing, and validation sets based on the provided proportions.\n",
    "- Stratifies the split based on the target feature to maintain the distribution of classes in each split.\n",
    "\n",
    "## Methods\n",
    "\n",
    "`load_data(file_path)`\\\n",
    "Loads data from a specified CSV file into a pandas DataFrame.\n",
    "\n",
    "- **Parameters:**\n",
    "  - `file_path` (str): Path to the CSV file.\n",
    "- **Returns:**\n",
    "  - `DataFrame`: A pandas DataFrame containing the loaded data.\n",
    "\n",
    "`type_data(self, type_data_merged)`\\\n",
    "Determines the type of data to use based on the provided parameter (`type_data_merged`).\n",
    "\n",
    "- **Parameters:**\n",
    "  - `type_data_merged` (int): Parameter to determine the type of data to use.\n",
    "\n",
    "`read_and_sample_data(self, base_path=\"../Data/cresci-2015.csv/\", type_data_merged=1, bot_ratio=[0.2, 0.8], bot_fldr_ratio=[1, 1, 1])`\\\n",
    "Reads and samples data from CSV files based on the provided parameters.\n",
    "\n",
    "- **Parameters:**\n",
    "  - `base_path` (str): The base directory containing the dataset files.\n",
    "  - `type_data_merged` (int): Type of data to use (merged or user-specific).\n",
    "  - `bot_ratio` (list): Desired ratio of bot samples in the final dataset.\n",
    "  - `bot_fldr_ratio` (list): Ratios of bot samples from different bot folders.\n",
    "\n",
    "`split_dataset(self, data, proportions=[0.7, 0.15, 0.15], target='bot')`\n",
    "Splits the dataset into training, testing, and validation sets.\n",
    "\n",
    "- **Parameters:**\n",
    "  - `data` (DataFrame): The DataFrame to split.\n",
    "  - `proportions` (list): Proportions of training, testing, and validation sets.\n",
    "  - `target` (str): The name of the target feature.\n",
    "- **Returns:**\n",
    "  - `dict`: A dictionary containing 'X_train', 'X_test', 'X_val', 'y_train', 'y_test', and 'y_val' DataFrames/Series.\n",
    "\n",
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importer = ImportData()\n",
    "\n",
    "# Read and sample data\n",
    "data = importer.read_and_sample_data()\n",
    "print(\"Sampled Data:\")\n",
    "print(data.head())\n",
    "\n",
    "# Split dataset\n",
    "split_data = importer.split_dataset(data)\n",
    "print(\"\\nSplit Data:\")\n",
    "for key, value in split_data.items():\n",
    "    print(f\"{key}: {len(value)}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FeatureSelection Class\n",
    "\n",
    "**Description**:\n",
    "This class is designed to perform feature selection on a given dataset for binary classification tasks. It supports three types of feature selection methods: correlation analysis, chi-squared test, and mutual information classifier. Additionally, it provides visualization capabilities such as pair plots and correlation heatmaps to assist in understanding the relationship between features and the target variable.\n",
    "\n",
    "**Attributes**:\n",
    "data: DataFrame: The input dataset containing both features and the target variable.\n",
    "X: DataFrame: Features of the dataset.\n",
    "y: Series: Target variable of the dataset.\n",
    "values: DataFrame: Stores the feature importance values obtained from feature selection methods.\n",
    "list_values: List: Stores the names of selected features.\n",
    "\n",
    "**Methods**:\n",
    "1. __init__(data): Constructor method that initializes the FeatureSelection object with the input dataset.\n",
    "\n",
    "2. select_features(type_selection): Method to select features based on the specified type of feature selection method. It returns a list of selected feature names.\n",
    "\n",
    "3. correlation(): Method to perform correlation analysis and rank features based on their correlation with the target variable.\n",
    "\n",
    "4. chi2(): Method to perform chi-squared test for feature selection and rank features based on their importance scores.\n",
    "\n",
    "5. mutual_classifier(): Method to compute feature importance using mutual information classifier and rank features accordingly.\n",
    "\n",
    "6. pair_plot(num_feat): Method to generate a pair plot of selected features, optionally specifying the number of features to include.\n",
    "\n",
    "7. correlation_map(num_feat): Method to generate a correlation heatmap of selected features, optionally specifying the number of features to include.\n",
    "\n",
    "**Parameters**:\\\n",
    "type_selection: str, default='correlation': Specifies the type of feature selection method to use ('correlation', 'chi2', or 'classifier').\n",
    "\n",
    "num_feat: {'all', int}, default='all': Specifies the number of features to include in pair plot and correlation heatmap. If 'all', all features are included; otherwise, an integer value determines the number of features.\n",
    "\n",
    "**Example usage**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FeatureSelection object\n",
    "fs = FeatureSelection(data)\n",
    "\n",
    "# Perform feature selection using correlation analysis\n",
    "selected_features = fs.select_features(type_selection='correlation')\n",
    "\n",
    "# Generate pair plot\n",
    "fs.pair_plot(num_feat=5)\n",
    "\n",
    "# Generate correlation heatmap\n",
    "fs.correlation_map(num_feat=10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dependencies**:\\\n",
    "pandas: For data manipulation and handling.\\\n",
    "seaborn: For visualization of pair plots and correlation heatmaps.\\\n",
    "matplotlib.pyplot: For additional customization of visualizations.\\\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModelTester Class\n",
    "\n",
    "## Description:\n",
    "The `ModelTester` class is designed to facilitate the testing and evaluation of machine learning models for binary classification tasks. It provides functionality for model initialization, parameter tuning via grid search, prediction generation, and model persistence. Additionally, it allows users to perform feature selection and specify the number of features to consider during model training and testing.\n",
    "\n",
    "## Attributes:\n",
    "- `X_train`: DataFrame: Training features.\n",
    "- `X_test`: DataFrame: Test features.\n",
    "- `X_val`: DataFrame: Validation features.\n",
    "- `y_train`: Series: Training target variable.\n",
    "- `y_test`: Series: Test target variable.\n",
    "- `y_val`: Series: Validation target variable.\n",
    "- `feature_importance`: List: Feature importance rankings.\n",
    "- `models`: Dictionary: Stores trained models.\n",
    "\n",
    "## Methods:\n",
    "\n",
    "1. `__init__(data_dict, feature_importance)`: Constructor method that initializes the `ModelTester` object with data and feature importance rankings.\n",
    "\n",
    "2. `load_models()`: Loads pre-trained models with parameters from the 'Parameters' folder.\n",
    "\n",
    "3. `change_model_parameters(model_name, new_params)`: Modifies parameters of the specified model.\n",
    "\n",
    "4. `save_current_parameters(model_name)`: Saves the current parameters of the specified model to the 'Parameters' folder.\n",
    "\n",
    "5. `fit_all_models(num_features=None)`: Fits all models with the training data.\n",
    "\n",
    "6. `grid_search(model_name, param_grid=None, scoring='f1', num_features=None, save_feature=False)`: Performs grid search to fine-tune parameters for the specified model.\n",
    "\n",
    "7. `predict_model(model_name, num_features=None)`: Generates predictions (class labels and probabilities) for the chosen model using test and validation data.\n",
    "\n",
    "## Parameters:\n",
    "\n",
    "- `data_dict`: Dictionary containing training, test, and validation data (X_train, X_test, X_val, y_train, y_test, y_val).\n",
    "- `feature_importance`: List of feature importance rankings.\n",
    "- `model_name`: Name of the model (e.g., 'logistic_regression', 'knn', 'svm', 'decision_tree').\n",
    "- `new_params`: Dictionary containing new parameter values for the specified model.\n",
    "- `param_grid`: Dictionary specifying the range of parameters for grid search.\n",
    "- `scoring`: Scoring metric for grid search optimization (default is 'f1').\n",
    "- `num_features`: Number of features to consider in model training and testing.\n",
    "- `save_feature`: Boolean indicating whether to save the best parameters obtained from grid search.\n",
    "\n",
    "## Example Usage:\n",
    "```python\n",
    "# Create ModelTester object\n",
    "tester = ModelTester(data_dict, feature_importance)\n",
    "\n",
    "# Perform grid search for logistic regression model\n",
    "best_params = tester.grid_search('logistic_regression')\n",
    "\n",
    "# Generate predictions for logistic regression model\n",
    "predictions = tester.predict_model('logistic_regression')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies:\n",
    "os: For file operations and directory manipulation.\\\n",
    "joblib: For model persistence.\\\n",
    "GridSearchCV: From sklearn.model_selection for parameter tuning.\\\n",
    "classification_report: From sklearn.metrics for generating classification reports."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TestEnvironment Class\n",
    "\n",
    "## Description:\n",
    "The `TestEnvironment` class facilitates the setup and execution of machine learning model testing in a controlled environment. It allows users to define various parameters related to dataset configuration, feature selection, model selection, hyperparameter tuning, and result saving. Additionally, it integrates data importation, feature selection, model testing, and result saving functionalities into a cohesive workflow.\n",
    "\n",
    "## Attributes:\n",
    "- `DATASET`: Name of the dataset.\n",
    "- `BOT_FOLDERS`: List of folders containing bot data.\n",
    "- `BOT_RATIO`: Ratio of bot data to total data.\n",
    "- `MERGED_DATASET`: Indicates whether the dataset is merged.\n",
    "- `TYPE_SELECTION`: Type of feature selection method.\n",
    "- `TRAIN_RATE`: Proportion of data used for training.\n",
    "- `TEST_RATE`: Proportion of data used for testing.\n",
    "- `VAL_RATE`: Proportion of data used for validation.\n",
    "- `MODEL`: Type of model to be tested.\n",
    "- `FEATURES`: Number of features to consider during testing.\n",
    "- `MODEL_P`: Dictionary of model parameters.\n",
    "- `GRID_SEARCH`: Boolean indicating whether to perform grid search.\n",
    "\n",
    "## Methods:\n",
    "\n",
    "1. `__init__(DATASET, BOT_FOLDERS, BOT_RATIO, MERGED_DATASET, TYPE_SELECTION, TRAIN_RATE, TEST_RATE, VAL_RATE, MODEL, FEATURES, MODEL_P, GRID_SEARCH)`: Constructor method that initializes the `TestEnvironment` object with specified parameters.\n",
    "\n",
    "2. `save_results(model_parametres, test_metrics, val_metrics, MODEL)`: Saves the testing results to a CSV file.\n",
    "\n",
    "3. `run_tests()`: Runs tests for the specified model(s) and returns the results.\n",
    "\n",
    "## Parameters:\n",
    "\n",
    "- `DATASET`: Name of the dataset to be tested.\n",
    "- `BOT_FOLDERS`: List of folders containing bot data.\n",
    "- `BOT_RATIO`: Ratio of bot data to total data.\n",
    "- `MERGED_DATASET`: Boolean indicating whether the dataset is merged.\n",
    "- `TYPE_SELECTION`: Type of feature selection method ('correlation', 'chi2', 'classifier').\n",
    "- `TRAIN_RATE`: Proportion of data used for training.\n",
    "- `TEST_RATE`: Proportion of data used for testing.\n",
    "- `VAL_RATE`: Proportion of data used for validation.\n",
    "- `MODEL`: Type of model to be tested ('all' or specific model name).\n",
    "- `FEATURES`: Number of features to consider during testing.\n",
    "- `MODEL_P`: Dictionary of model parameters for hyperparameter tuning.\n",
    "- `GRID_SEARCH`: Boolean indicating whether to perform grid search for hyperparameter tuning.\n",
    "\n",
    "## Example Usage:\n",
    "```python\n",
    "# Create TestEnvironment object\n",
    "env = TestEnvironment(DATASET, BOT_FOLDERS, BOT_RATIO, MERGED_DATASET, TYPE_SELECTION, TRAIN_RATE, TEST_RATE, VAL_RATE, MODEL, FEATURES, MODEL_P, GRID_SEARCH)\n",
    "\n",
    "# Run tests\n",
    "results = env.run_tests()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies:\n",
    "- `os`: For file operations and directory manipulation.\\\n",
    "- `pandas`: For data manipulation and handling.\\\n",
    "- `ImportData`: Custom class for importing data.\\\n",
    "- `Evaluate`: Custom class for model evaluation.\\\n",
    "- `FeatureSelection`: Custom class for feature selection.\\\n",
    "- `ModelTester`: Custom class for model testing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
